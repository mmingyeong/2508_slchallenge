# predict.py
# -*- coding: utf-8 -*-
"""
Predict / evaluate script for binary strong-lensing classification using ConvNeXt V2.

Now supports passing preprocessing toggles to data_loader:
- padding: --apply_padding, --out_size_when_padded
- normalization: --apply_normalization, --clip_q, --low_clip_q, --use_mad
- smoothing: --smoothing_mode {none,gaussian,guided}, --gaussian_sigma, --guided_radius, --guided_eps
"""

import os
import csv
import argparse
import logging
from typing import Dict, Tuple, List, Optional
from contextlib import nullcontext

import numpy as np
import torch
from sklearn.metrics import accuracy_score, roc_auc_score
from tqdm import tqdm

from data_loader import get_dataloaders
from model import convnextv2_atto, convnextv2_nano, convnextv2_tiny


# ---------------------------
# Logging
# ---------------------------
def setup_logger(log_file: str | None = None) -> logging.Logger:
    handlers = [logging.StreamHandler()]
    if log_file:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        handlers.append(logging.FileHandler(log_file, mode="w", encoding="utf-8"))
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] [predict] %(message)s",
        handlers=handlers,
        force=True,
    )
    return logging.getLogger("predict")


# ---------------------------
# Eval helper
# ---------------------------
@torch.no_grad()
def run_inference(
    model: torch.nn.Module,
    loader,
    device: torch.device,
    desc: str = "Predict",
    max_samples: Optional[int] = None,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str], List[str]]:
    """
    Returns:
      labels (N,), probs (N,), preds (N,), paths (list[str]), domains (list[str])
    """
    model.eval()
    all_labels, all_probs, all_preds = [], [], []
    all_paths, all_domains = [], []

    pbar = tqdm(loader, desc=desc, leave=False)
    amp_ctx = torch.amp.autocast(device_type=device.type) if device.type == "cuda" else nullcontext()

    seen = 0
    for imgs, labels, metas in pbar:
        if max_samples is not None and seen >= max_samples:
            break

        imgs = imgs.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True).float().unsqueeze(1)

        with amp_ctx:
            logits = model(imgs)

        probs = torch.sigmoid(logits).cpu().numpy().squeeze()
        preds = (probs > 0.5).astype(np.int32)
        ys    = labels.cpu().numpy().squeeze()

        probs = np.atleast_1d(probs)
        preds = np.atleast_1d(preds)
        ys    = np.atleast_1d(ys)

        if max_samples is not None:
            remain = max_samples - seen
            if probs.shape[0] > remain:
                probs = probs[:remain]
                preds = preds[:remain]
                ys    = ys[:remain]
                metas = metas[:remain]

        all_probs.append(probs)
        all_preds.append(preds)
        all_labels.append(ys)

        for m in metas:
            all_paths.append(m["path"])
            all_domains.append(m["domain"])

        seen += probs.shape[0]

    labels = np.concatenate(all_labels) if all_labels else np.array([])
    probs  = np.concatenate(all_probs)  if all_probs  else np.array([])
    preds  = np.concatenate(all_preds)  if all_preds  else np.array([])

    n = min(len(labels), len(probs), len(preds), len(all_paths), len(all_domains))
    return labels[:n], probs[:n], preds[:n], all_paths[:n], all_domains[:n]


def build_model(model_size: str, drop_path: float, device: torch.device) -> torch.nn.Module:
    factory = {
        "atto": convnextv2_atto,
        "nano": convnextv2_nano,
        "tiny": convnextv2_tiny,
    }
    model = factory[model_size](in_chans=1, num_classes=1, drop_path_rate=drop_path).to(device)
    return model


# ---------------------------
# Main
# ---------------------------
def main(args):
    logger = setup_logger(os.path.join(args.output_dir, "predict.log"))
    device = torch.device(args.device)

    # Build dataloaders (same split as train)
    class_paths: Dict[str, str] = {
        "slsim_lenses": args.slsim_lenses,
        "slsim_nonlenses": args.slsim_nonlenses,
        "hsc_lenses": args.hsc_lenses,
        "hsc_nonlenses": args.hsc_nonlenses,
    }
    logger.info("üì¶ Building dataloaders...")

    # ----- SAFE READ of optional smoothing args -----
    smoothing_mode_raw = getattr(args, "smoothing_mode", "none")
    smoothing_mode = None if (smoothing_mode_raw is None or str(smoothing_mode_raw).lower() == "none") \
                     else str(smoothing_mode_raw).lower()

    gaussian_sigma = float(getattr(args, "gaussian_sigma", 1.0))
    guided_radius  = int(getattr(args, "guided_radius", 2))
    guided_eps     = float(getattr(args, "guided_eps", 1e-3))

    # clip_q ÏùåÏàò ‚Üí None
    clip_q = getattr(args, "clip_q", 0.997)
    if clip_q is not None and clip_q < 0:
        clip_q = None

    train_loader, val_loader, test_loader = get_dataloaders(
        class_paths=class_paths,
        batch_size=args.batch_size,
        split=(args.train_frac, args.val_frac, args.test_frac),
        seed=args.seed,
        num_workers=args.num_workers,
        pin_memory=True,
        augment_train=False,  # prediction ‚Üí no augment
        # debug sampling
        take_train_fraction=getattr(args, "take_train_fraction", None),
        take_val_fraction=getattr(args, "take_val_fraction", None),
        take_test_fraction=getattr(args, "take_test_fraction", None),
        # --- preprocessing toggles (pass-through) ---
        apply_padding=getattr(args, "apply_padding", False),
        out_size_when_padded=getattr(args, "out_size_when_padded", 64),
        apply_normalization=getattr(args, "apply_normalization", False),
        clip_q=clip_q,
        low_clip_q=getattr(args, "low_clip_q", None),
        use_mad=getattr(args, "use_mad", False),
        # smoothing
        smoothing_mode=smoothing_mode,            # None | "gaussian" | "guided"
        gaussian_sigma=gaussian_sigma,
        guided_radius=guided_radius,
        guided_eps=guided_eps,
    )
    logger.info(f"Split sizes -> train:{len(train_loader.dataset)}  "
                f"val:{len(val_loader.dataset)}  test:{len(test_loader.dataset)}")

    # Choose which split(s)
    which = args.which.lower()
    selected = []
    if which in ("train", "all"):
        selected.append(("train", train_loader))
    if which in ("val", "valid", "validation", "all"):
        selected.append(("val", val_loader))
    if which in ("test", "all"):
        selected.append(("test", test_loader))
    if not selected:
        raise ValueError(f"Invalid --which '{args.which}'. Choose from train/val/test/all.")

    # Model + checkpoint
    logger.info("üß† Loading model...")
    model = build_model(args.model_size, args.drop_path, device)
    state = torch.load(args.model_path, map_location=device)
    model.load_state_dict(state["model"] if isinstance(state, dict) and "model" in state else state)

    os.makedirs(args.output_dir, exist_ok=True)

    # Inference per split
    for tag, loader in selected:
        logger.info(f"üöÄ Inference on split: {tag}")
        labels, probs, preds, paths, domains = run_inference(
            model, loader, device, desc=f"Predict-{tag}", max_samples=getattr(args, "max_samples", None)
        )

        # Metrics
        acc = accuracy_score(labels, preds) if labels.size else float("nan")
        try:
            auc = roc_auc_score(labels, probs) if labels.size else float("nan")
        except ValueError:
            auc = float("nan")
        logger.info(f"‚úÖ {tag.upper()} | Acc={acc:.4f} | AUC={auc:.4f} | N={labels.size}")

        # Save CSV
        csv_path = os.path.join(args.output_dir, f"pred_{tag}.csv")
        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["path", "domain", "label", "prob", "pred"])
            for p, d, y, pr, pd in zip(paths, domains, labels.tolist(), probs.tolist(), preds.tolist()):
                writer.writerow([p, d, y, pr, pd])
        logger.info(f"üíæ Saved per-sample CSV ‚Üí {csv_path}")

        # Save NPY
        np.save(os.path.join(args.output_dir, f"labels_{tag}.npy"), labels)
        np.save(os.path.join(args.output_dir, f"probs_{tag}.npy"), probs)
        np.save(os.path.join(args.output_dir, f"preds_{tag}.npy"), preds)
        logger.info(f"üíæ Saved NPY arrays for {tag} split")

    logger.info("üéØ Done.")


# ---------------------------
# CLI
# ---------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Predict/evaluate ConvNeXt V2 on FITS (binary classification)")
    # Data dirs
    parser.add_argument("--slsim_lenses",      type=str, required=True)
    parser.add_argument("--slsim_nonlenses",   type=str, required=True)
    parser.add_argument("--hsc_lenses",        type=str, required=True)
    parser.add_argument("--hsc_nonlenses",     type=str, required=True)
    # Which split
    parser.add_argument("--which",             type=str, default="test",
                        help="train | val | test | all")
    # Loader (split)
    parser.add_argument("--batch_size",        type=int, default=128)
    parser.add_argument("--num_workers",       type=int, default=8)
    parser.add_argument("--train_frac",        type=float, default=0.70)
    parser.add_argument("--val_frac",          type=float, default=0.15)
    parser.add_argument("--test_frac",         type=float, default=0.15)
    parser.add_argument("--seed",              type=int, default=42)
    # Debug subsampling
    parser.add_argument("--take_train_fraction", type=float, default=None)
    parser.add_argument("--take_val_fraction",   type=float, default=None)
    parser.add_argument("--take_test_fraction",  type=float, default=None)
    # Model
    parser.add_argument("--model_path",        type=str, required=True)
    parser.add_argument("--model_size",        type=str, default="atto", choices=["atto", "nano", "tiny"])
    parser.add_argument("--drop_path",         type=float, default=0.0)
    # Runtime
    parser.add_argument("--device",            type=str, default="cuda" if torch.cuda.is_available() else "cpu")
    parser.add_argument("--output_dir",        type=str, default="./pred_outputs")
    parser.add_argument("--max_samples",       type=int, default=None)

    # ===== Preprocessing toggles (pass-through to data_loader) =====
    # Padding
    parser.add_argument("--apply_padding", action="store_true",
                        help="Center pad 41x41 -> out_size_when_padded (constant background).")
    parser.add_argument("--out_size_when_padded", type=int, default=64)

    # Normalization
    parser.add_argument("--apply_normalization", action="store_true",
                        help="Background subtraction -> (optional clip) -> z-score (or MAD).")
    parser.add_argument("--clip_q", type=float, default=0.997,
                        help="High-quantile clipping; set <0 to disable (plain z-score).")
    parser.add_argument("--low_clip_q", type=float, default=None,
                        help="Optional low-tail clipping quantile (e.g., 0.005).")
    parser.add_argument("--use_mad", action="store_true",
                        help="Use robust median/MAD instead of mean/std for z-score.")

    # Smoothing
    parser.add_argument("--smoothing_mode", type=str, default="none",
                        choices=["none", "gaussian", "guided"],
                        help="Apply smoothing before padding: none | gaussian | guided.")
    parser.add_argument("--gaussian_sigma", type=float, default=1.0,
                        help="Gaussian sigma in pixels (only if smoothing_mode=gaussian).")
    parser.add_argument("--guided_radius",  type=int,   default=2,
                        help="Guided filter radius in pixels (only if smoothing_mode=guided).")
    parser.add_argument("--guided_eps",     type=float, default=1e-3,
                        help="Guided filter regularization epsilon (only if smoothing_mode=guided).")


    args = parser.parse_args()

    if args.clip_q is not None and args.clip_q < 0:
        args.clip_q = None

    main(args)
